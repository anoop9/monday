{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f317e44-04d4-4a47-ab08-c36257350d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated KPIs:\n",
      "     Group  Users  Revenue_D1  Retained_D1  ARPI_D1  D1_Retention\n",
      "0  Control  10000        4500         3200     0.45          0.32\n",
      "1     Test  10000        4800         3500     0.48          0.35\n",
      "\n",
      "\n",
      "ARPI_D1 Control: 0.4500\n",
      "ARPI_D1 Test: 0.4800\n",
      "Difference in ARPI_D1: 0.0300\n",
      "Z-statistic for ARPI_D1: 2.1213\n",
      "P-value for ARPI_D1: 0.0339 (based on hypothetical individual revenue std dev)\n",
      "\n",
      "ARPI_D1 Significance Test (assuming individual revenue std dev = $1.5):\n",
      "  Control ARPI_D1: $0.4500\n",
      "  Test ARPI_D1: $0.4800\n",
      "  Difference: $0.0300\n",
      "  Z-statistic: 1.4142\n",
      "  P-value: 0.1573\n",
      "  Result: No statistically significant improvement in ARPI_D1 at alpha=0.05\n",
      "\n",
      "\n",
      "D1 Retention Significance Test:\n",
      "  Control D1 Retention: 0.3200\n",
      "  Test D1 Retention: 0.3500\n",
      "  Difference: 0.0300\n",
      "  Z-statistic: 4.4944\n",
      "  P-value: 0.0000\n",
      "  Result: Statistically significant improvement in D1 Retention at alpha=0.05\n",
      "\n",
      "\n",
      "Power for ARPI_D1 (based on observed effect and assumed individual revenue std dev = $1.5):\n",
      "  Observed Effect (diff_arpi): 0.0300\n",
      "  Standard Error of Difference (SE_diff_arpi): 0.0212\n",
      "  Calculated Power: 0.2930\n",
      "  Required Sample Size per group for 80% Power (ARPI_D1): 39,245\n",
      "  Current Sample Size per group: 10,000\n",
      "  Conclusion: Insufficient sample size for ARPI_D1 (based on observed effect and assumed std dev).\n",
      "\n",
      "\n",
      "Power for D1 Retention (based on observed effect):\n",
      "  Observed Effect (diff_retention): 0.0300\n",
      "  Standard Error of Difference (SE_diff_retention): 0.0067\n",
      "  Calculated Power: 0.9944\n",
      "  Required Sample Size per group for 80% Power (D1 Retention): 3,882\n",
      "  Current Sample Size per group: 10,000\n",
      "  Conclusion: Sufficient sample size for D1 Retention (based on observed effect).\n",
      "\n",
      "\n",
      "--- Summary of Findings and Recommendation ---\n",
      "1. Statistical Significance Assessment:\n",
      "   - ARPI_D1: P-value = 0.1573. With alpha = 0.05, the feature is NOT statistically significant for ARPI_D1.\n",
      "     (Note: This result for ARPI_D1 is based on an assumed standard deviation of individual D1 revenue. In a real scenario, this assumption would need to be validated with granular data.)\n",
      "   - D1 Retention: P-value = 0.0000. With alpha = 0.05, the feature is statistically significant for D1 Retention.\n",
      "\n",
      "2. Power of the Test and Sample Size:\n",
      "   - ARPI_D1: Calculated Power = 0.2930. Required sample size for 80% power for the observed effect = 39,245.\n",
      "     The current sample size of 10,000 users per group was INSUFFICIENT for ARPI_D1 (given the assumed individual revenue std dev).\n",
      "   - D1 Retention: Calculated Power = 0.9944. Required sample size for 80% power for the observed effect = 3,882.\n",
      "     The current sample size of 10,000 users per group was sufficient for D1 Retention.\n",
      "\n",
      "3. Recommendation:\n",
      "a. Should the feature be rolled out? CONSIDER CAREFULLY. While D1 Retention shows a statistically significant improvement, ARPI_D1 does not (based on the current assumptions).\n",
      "b. Is there enough evidence? Partially. There is strong evidence for D1 Retention improvement. For ARPI_D1, the evidence is not strong enough for statistical significance under the current assumptions.\n",
      "c. If not significant (for ARPI_D1):\n",
      "   - Investigate the assumed individual revenue standard deviation for ARPI_D1 more accurately, potentially by getting granular user-level data.\n",
      "   - If the current data setup is robust, consider running the test for a longer duration to gather more data and increase the sample size effectively, or increase the sample size for a new test.\n",
      "   - Analyze qualitative feedback about the feature to understand user perception and identify potential reasons for non-significant ARPI improvement.\n",
      "   - Re-evaluate the feature's potential business impact. If the D1 retention uplift is valuable enough on its own, it might warrant rollout even without ARPI_D1 significance, but this depends on business priorities.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Data Definition\n",
    "# Define the given data\n",
    "data = {\n",
    "    'Group': ['Control', 'Test'],\n",
    "    'Users': [10000, 10000],\n",
    "    'Revenue_D1': [4500, 4800],\n",
    "    'Retained_D1': [3200, 3500]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate KPIs\n",
    "df['ARPI_D1'] = df['Revenue_D1'] / df['Users']\n",
    "df['D1_Retention'] = df['Retained_D1'] / df['Users']\n",
    "\n",
    "print(\"Calculated KPIs:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Statistical Significance Assessment\n",
    "\n",
    "## 2.1 ARPI_D1 Significance Test\n",
    "\n",
    "# For ARPI_D1, we are comparing means. Since we have revenue data, we can consider the total revenue\n",
    "# and the number of users to estimate the standard deviation or use a t-test directly.\n",
    "# However, for simplicity and given the assumption of approximate normality for ARPI,\n",
    "# we'll use a two-sample t-test. To do this, we need to estimate the standard deviation\n",
    "# of individual ARPI. Given we only have aggregate revenue, a more robust approach\n",
    "# for ARPI (which is a ratio) often involves bootstrapping or delta method for its standard error.\n",
    "# But adhering to the assumption of ARPI being approximately normally distributed,\n",
    "# and for a practical business context, we will proceed by calculating the standard error\n",
    "# of the mean ARPI. Without individual user revenue data, we'll make a simplifying assumption\n",
    "# for variance or proceed with an approximate method.\n",
    "\n",
    "# A more appropriate way for ARPI given aggregate data and large sample sizes is to use\n",
    "# a z-test for difference in means, where the standard error of ARPI can be estimated\n",
    "# from the overall variance of revenue per user. If we don't have this, we need to estimate.\n",
    "# For simplicity, and as ARPI is assumed approximately normally distributed, we can\n",
    "# treat this as a comparison of two population means.\n",
    "\n",
    "# Let's assume for ARPI_D1 that the variance of individual user revenue is similar between groups.\n",
    "# We will estimate the standard deviation of ARPI for each group.\n",
    "# A common way to estimate the standard error of the mean when you only have aggregate data\n",
    "# and assume normality of the underlying metric (ARPI) is to consider the variance of the\n",
    "# total revenue and divide by N^2.\n",
    "\n",
    "# However, a more practical approach for ARPI in an A/B test context, especially if treating\n",
    "# it as approximately normal and assuming equal variances, is to use a pooled standard\n",
    "# deviation or to assume we have enough individual data points that the Central Limit\n",
    "# Theorem applies well to the average.\n",
    "\n",
    "# Let's use a conservative approach and approximate the standard error of ARPI.\n",
    "# Without individual user revenue data, it's hard to get the exact standard deviation.\n",
    "# A common simplification is to assume that the standard deviation of ARPI is proportional\n",
    "# to ARPI itself, or to use a surrogate for variance.\n",
    "\n",
    "# For a ratio metric like ARPI, a common approach for hypothesis testing is to use a t-test\n",
    "# or z-test on the difference of means. For large samples, a z-test is appropriate.\n",
    "# The standard error of the difference in means for two independent samples is:\n",
    "# SE_diff = sqrt( (s1^2 / n1) + (s2^2 / n2) )\n",
    "# Where s1 and s2 are standard deviations of ARPI for each group.\n",
    "\n",
    "# Since we don't have standard deviations, we need to estimate them.\n",
    "# A common (though simplified) approach for ARPI, if we don't have full distribution,\n",
    "# is to assume that the standard deviation of ARPI_D1 is some proportion of the mean ARPI_D1,\n",
    "# or to acknowledge the limitation and proceed with the data we have.\n",
    "\n",
    "# Given the simplification, let's treat ARPI_D1 as a sample mean and perform a z-test.\n",
    "# To do a Z-test or t-test, we need an estimate of the standard deviation of the ARPI for each user.\n",
    "# Since we don't have this, we cannot directly calculate standard error of ARPI_D1\n",
    "# without making strong assumptions or using a more complex model (e.g., assuming a distribution\n",
    "# for individual revenue like Gamma or Log-Normal).\n",
    "\n",
    "# For A/B testing on ARPU/ARPI, a common method is to perform a t-test if individual\n",
    "# user data (revenue per user) is available to calculate sample variance.\n",
    "# Since we have aggregate data, we cannot directly apply standard t-test formulas\n",
    "# for the mean of individual revenues.\n",
    "\n",
    "# Let's re-evaluate the assumption \"ARPI is approximately normally distributed.\"\n",
    "# This implies that the sample means of ARPI are normally distributed.\n",
    "# To test the difference, we still need standard errors.\n",
    "\n",
    "# A common way around this for aggregate data in A/B tests is to treat the total revenue\n",
    "# as the sum of many independent random variables. If we assume individual user revenue\n",
    "# follows some distribution, then the sum (total revenue) will be approximately normal\n",
    "# for large N.\n",
    "\n",
    "# Let's make an assumption for the standard deviation for the purpose of calculation.\n",
    "# If we were to assume a coefficient of variation (CV) for individual user revenue, say 2.0 (meaning std dev is 2x mean),\n",
    "# then std_dev_individual = CV * ARPI_D1.\n",
    "# Variance of ARPI_D1 = (std_dev_individual^2) / N = (CV * ARPI_D1)^2 / N.\n",
    "# This is a strong assumption without data.\n",
    "\n",
    "# A more robust approach for ARPI given aggregate data and assuming normality of the *mean* ARPI\n",
    "# (due to CLT) is to calculate the variance of the sample mean.\n",
    "# But we don't have individual sample variances.\n",
    "\n",
    "# Alternative: Test for difference in proportions for D1 Retention, and for ARPI_D1,\n",
    "# acknowledge the limitation of not having individual revenue data and proceed with a simplified approach.\n",
    "\n",
    "# Let's simplify ARPI_D1 test for the sake of demonstration given the prompt constraints.\n",
    "# If we assume we could estimate the standard deviation of ARPI for individual users,\n",
    "# let's assume a hypothetical standard deviation for ARPI.\n",
    "# For example, let's assume the standard deviation of individual user's D1 revenue is $1.0 for both groups.\n",
    "# This is a major assumption and should be stated clearly.\n",
    "# If we assume standard deviation of revenue per user (s_ind_rev) is constant and known, e.g., $1.0.\n",
    "s_ind_rev = 1.0 # Hypothetical standard deviation of individual user's D1 revenue\n",
    "# This is a very strong assumption and if I had to do this in a real scenario,\n",
    "# I would strongly push back for more granular data or make a more data-driven assumption.\n",
    "\n",
    "# Standard error of ARPI_D1 (mean revenue per user) = s_ind_rev / sqrt(N)\n",
    "se_control_arpi = s_ind_rev / np.sqrt(df.loc[0, 'Users'])\n",
    "se_test_arpi = s_ind_rev / np.sqrt(df.loc[1, 'Users'])\n",
    "\n",
    "# Z-statistic for difference in means\n",
    "diff_arpi = df.loc[1, 'ARPI_D1'] - df.loc[0, 'ARPI_D1']\n",
    "se_diff_arpi = np.sqrt(se_control_arpi**2 + se_test_arpi**2)\n",
    "z_arpi = diff_arpi / se_diff_arpi\n",
    "p_value_arpi = 2 * (1 - stats.norm.cdf(abs(z_arpi))) # Two-tailed test\n",
    "\n",
    "print(f\"ARPI_D1 Control: {df.loc[0, 'ARPI_D1']:.4f}\")\n",
    "print(f\"ARPI_D1 Test: {df.loc[1, 'ARPI_D1']:.4f}\")\n",
    "print(f\"Difference in ARPI_D1: {diff_arpi:.4f}\")\n",
    "print(f\"Z-statistic for ARPI_D1: {z_arpi:.4f}\")\n",
    "print(f\"P-value for ARPI_D1: {p_value_arpi:.4f} (based on hypothetical individual revenue std dev)\\n\")\n",
    "\n",
    "# A more practical approach for ARPI without individual data is to consider the distribution of total revenue.\n",
    "# If total revenue is assumed to be normally distributed, then:\n",
    "# Mean of total revenue (Control) = 4500, Mean of total revenue (Test) = 4800\n",
    "# However, we're testing ARPI_D1, which is mean revenue per user.\n",
    "\n",
    "# Let's consider a scenario where we approximate the variance of the sum directly.\n",
    "# If we assume the revenue per user is approximately normal, then the sample mean ARPI_D1\n",
    "# is also approximately normal. We need the standard deviation of ARPI_D1.\n",
    "# Without actual individual revenue data, this is a major limitation.\n",
    "\n",
    "# For a robust approach for ARPI_D1, it's best to use a bootstrapping method or\n",
    "# to model the revenue data directly (e.g., if it's count data, a Poisson or Negative Binomial\n",
    "# regression, if continuous and skewed, log-normal).\n",
    "# Given the prompt, and the assumption \"ARPI is approximately normally distributed\",\n",
    "# implies the *distribution of sample means* of ARPI is normal.\n",
    "# For hypothesis testing, we need standard errors.\n",
    "\n",
    "# A more common way to deal with ARPI when you have aggregate data is to use a method\n",
    "# that accounts for the sum, or if you can assume the variance of individual users' ARPI.\n",
    "# If we assume that the revenue per user is normally distributed, and that the standard deviation\n",
    "# of individual user revenue is *not* given, then we cannot perform the z-test precisely.\n",
    "\n",
    "# Let's proceed with a common heuristic for A/B testing on ARPI:\n",
    "# If we don't have individual user data, we often calculate the variance of the *total* revenue.\n",
    "# However, for ARPI (mean), we need the variance of the mean.\n",
    "\n",
    "# A more practical approach without individual data:\n",
    "# For ARPI, if we were to assume a certain level of variability in individual user revenue,\n",
    "# we could estimate the standard error.\n",
    "# If we cannot estimate std dev of individual ARPI, we cannot perform the t-test or z-test properly.\n",
    "\n",
    "# Let's reconsider the problem statement carefully: \"ARPI is approximately normally distributed\".\n",
    "# This could mean the *sample mean* ARPI is normal.\n",
    "# However, for hypothesis testing, we need the standard deviation of these sample means.\n",
    "\n",
    "# If we were to assume a common standard deviation for individual user revenues across groups,\n",
    "# say we derived it from historical data or industry benchmarks, then we could use it.\n",
    "# Without such data, any result is highly dependent on this assumed std dev.\n",
    "\n",
    "# Let's try to use the idea of a pooled standard deviation from the data we have,\n",
    "# but acknowledging this is an approximation for aggregate data.\n",
    "# This part is tricky without individual data or specific assumptions about revenue distribution.\n",
    "\n",
    "# Given the limitations of the prompt, let's assume the prompt *implies* that we have\n",
    "# enough information to proceed with standard hypothesis tests for means.\n",
    "# A practical approximation for the standard deviation of ARPI, if we treat total revenue as a sum\n",
    "# and assume revenue per user is non-negative and potentially skewed, a robust standard error\n",
    "# could be estimated via bootstrapping from individual user data (which we don't have).\n",
    "\n",
    "# Let's use an alternative for ARPI for demonstration, assuming the standard error of the mean\n",
    "# can be approximated by a common method for A/B tests if we assume a certain variance model\n",
    "# for the underlying data.\n",
    "# A common pattern for A/B test analysis of ARPI when only aggregate data is provided\n",
    "# is to fall back on the idea that the total revenue is a sum, and if individual revenues\n",
    "# are roughly independent, the total revenue is approximately normally distributed.\n",
    "# However, this doesn't directly give the variance of the *mean*.\n",
    "\n",
    "# Let's assume, for the purpose of the exercise, that the variance of ARPI is somehow\n",
    "# known or estimable, or that we're supposed to proceed with a simplification.\n",
    "# Since we are given \"ARPI is approximately normally distributed\", let's assume it means\n",
    "# the *sample mean* itself.\n",
    "\n",
    "# A common way to estimate the variance of a ratio like ARPI is using the Delta method\n",
    "# if we had the variance of revenue and users, and their covariance.\n",
    "# Given the simplified sample, it's highly probable the exercise intends a simpler approach.\n",
    "\n",
    "# Let's proceed with the most straightforward interpretation for ARPI:\n",
    "# If the ARPI itself is normally distributed, then we need sample variance of ARPI.\n",
    "# If we don't have individual data, we cannot calculate the true sample variance of ARPI.\n",
    "\n",
    "# Let's state the limitation and make a necessary assumption to proceed with ARPI.\n",
    "# For ARPI, we are comparing means. To perform a z-test or t-test, we need the standard\n",
    "# deviation of the sample mean. Without individual user data, we cannot compute this directly.\n",
    "# Let's assume that for the purpose of this exercise, we can use a pooled standard deviation\n",
    "# or assume an approximate standard deviation for each user's D1 revenue.\n",
    "\n",
    "# Let's assume the standard deviation of individual user's D1 revenue is the same for both groups.\n",
    "# And let's assume a realistic value for it, e.g., 2 times the average ARPI, reflecting typical\n",
    "# skewed revenue distributions.\n",
    "std_dev_individual_revenue_control = 2 * df.loc[0, 'ARPI_D1']\n",
    "std_dev_individual_revenue_test = 2 * df.loc[1, 'ARPI_D1']\n",
    "# Since we want to use a pooled std dev for the t-test assuming equal variances,\n",
    "# let's calculate a pooled std dev based on these assumed individual std devs.\n",
    "# This is still a strong assumption.\n",
    "\n",
    "# A more robust approach for ARPI:\n",
    "# For ARPI, especially when dealing with aggregate data, a common method is to use a bootstrap\n",
    "# to estimate confidence intervals and p-values if individual data is available.\n",
    "# Since it's not, and assuming \"ARPI is approximately normally distributed\", we will assume that\n",
    "# this implies the *sample mean* ARPI is approximately normally distributed, and we need its SE.\n",
    "\n",
    "# Let's try to interpret \"ARPI is approximately normally distributed\" as meaning that\n",
    "# the underlying individual revenue values are such that the sample mean ARPI is well-behaved.\n",
    "# For A/B tests, it is common to assume that the underlying revenue data is approximately normal\n",
    "# for large sample sizes, and perform a t-test.\n",
    "\n",
    "# Let's compute the standard error of the mean for ARPI based on an assumed standard deviation for individual revenue.\n",
    "# A reasonable approximation if not given individual variance:\n",
    "# Let's assume we have prior knowledge that the standard deviation of individual revenue per user\n",
    "# is roughly $1.0 (a common simple assumption in such problems without full data).\n",
    "std_dev_user_revenue = 1.0 # For illustration. In reality, this needs data.\n",
    "\n",
    "n_control = df.loc[0, 'Users']\n",
    "n_test = df.loc[1, 'Users']\n",
    "\n",
    "mean_arpi_control = df.loc[0, 'ARPI_D1']\n",
    "mean_arpi_test = df.loc[1, 'ARPI_D1']\n",
    "\n",
    "# Z-test for ARPI_D1 (difference in means, with assumed std dev for individual revenue)\n",
    "# This assumes we know the population standard deviation for individual revenue.\n",
    "# If we don't, we'd use a t-test, and would need sample standard deviations.\n",
    "# Given this constraint, I will assume a standard deviation for individual revenue for the calculation.\n",
    "\n",
    "# This is a critical point: without the standard deviation of individual revenue per user,\n",
    "# we cannot accurately compute the standard error of ARPI_D1.\n",
    "# If I had to make an assumption to proceed, I would state it clearly.\n",
    "# Let's assume the prompt implicitly wants us to perform a t-test on the means,\n",
    "# and we have to approximate or infer the standard deviations.\n",
    "\n",
    "# Let's reconsider. Maybe the intent is to use a statistical test suitable for total sums,\n",
    "# or to acknowledge the limitation.\n",
    "# If \"ARPI is approximately normally distributed\" means the *individual* ARPIs are normal,\n",
    "# then we'd need their standard deviation.\n",
    "# If it means the *sample mean* ARPIs are normal, then we still need the standard error.\n",
    "\n",
    "# Given the simplified data, and the common context of A/B tests,\n",
    "# I will proceed with a simplified approach for ARPI_D1 by assuming a pooled variance\n",
    "# that can be estimated if we knew the variance of individual user revenues.\n",
    "# Since we don't have individual revenue values, a direct application of t-test is difficult.\n",
    "\n",
    "# Let's try to make a reasonable assumption for the standard deviation of individual revenue.\n",
    "# Say, the variance of individual D1 revenue is 100 times the mean ARPI_D1. (arbitrary, but common patterns for skewed data).\n",
    "# Let's assume the variance of individual D1 revenue is roughly constant across groups, e.g., $10 per user.\n",
    "# Let's assume standard deviation of individual D1 revenue = $1.5 per user. (Arbitrary practical estimate if forced)\n",
    "s_ind_revenue_assumed = 1.5\n",
    "\n",
    "se_control_arpi = s_ind_revenue_assumed / np.sqrt(df.loc[0, 'Users'])\n",
    "se_test_arpi = s_ind_revenue_assumed / np.sqrt(df.loc[1, 'Users'])\n",
    "\n",
    "diff_arpi = mean_arpi_test - mean_arpi_control\n",
    "se_diff_arpi = np.sqrt(se_control_arpi**2 + se_test_arpi**2)\n",
    "z_arpi = diff_arpi / se_diff_arpi\n",
    "p_value_arpi = 2 * (1 - stats.norm.cdf(abs(z_arpi))) # Two-tailed test\n",
    "\n",
    "print(f\"ARPI_D1 Significance Test (assuming individual revenue std dev = ${s_ind_revenue_assumed}):\")\n",
    "print(f\"  Control ARPI_D1: ${mean_arpi_control:.4f}\")\n",
    "print(f\"  Test ARPI_D1: ${mean_arpi_test:.4f}\")\n",
    "print(f\"  Difference: ${diff_arpi:.4f}\")\n",
    "print(f\"  Z-statistic: {z_arpi:.4f}\")\n",
    "print(f\"  P-value: {p_value_arpi:.4f}\")\n",
    "alpha = 0.05\n",
    "if p_value_arpi < alpha:\n",
    "    print(f\"  Result: Statistically significant improvement in ARPI_D1 at alpha={alpha}\")\n",
    "else:\n",
    "    print(f\"  Result: No statistically significant improvement in ARPI_D1 at alpha={alpha}\")\n",
    "print(\"\\n\")\n",
    "# Important note: The ARPI_D1 result is highly dependent on the assumed individual revenue standard deviation.\n",
    "# In a real scenario, this would be derived from actual user-level revenue data.\n",
    "\n",
    "## 2.2 D1 Retention Significance Test (Proportion Test)\n",
    "\n",
    "# Number of users\n",
    "n_control = df.loc[0, 'Users']\n",
    "n_test = df.loc[1, 'Users']\n",
    "\n",
    "# Number of retained users\n",
    "retained_control = df.loc[0, 'Retained_D1']\n",
    "retained_test = df.loc[1, 'Retained_D1']\n",
    "\n",
    "# D1 Retention rates\n",
    "p_control = df.loc[0, 'D1_Retention']\n",
    "p_test = df.loc[1, 'D1_Retention']\n",
    "\n",
    "# Z-test for difference in proportions\n",
    "# Pooled proportion\n",
    "p_pooled = (retained_control + retained_test) / (n_control + n_test)\n",
    "\n",
    "# Standard error of the difference in proportions\n",
    "se_diff_retention = np.sqrt(p_pooled * (1 - p_pooled) * (1/n_control + 1/n_test))\n",
    "\n",
    "# Z-statistic\n",
    "z_retention = (p_test - p_control) / se_diff_retention\n",
    "\n",
    "# P-value (two-tailed test)\n",
    "p_value_retention = 2 * (1 - stats.norm.cdf(abs(z_retention)))\n",
    "\n",
    "print(\"D1 Retention Significance Test:\")\n",
    "print(f\"  Control D1 Retention: {p_control:.4f}\")\n",
    "print(f\"  Test D1 Retention: {p_test:.4f}\")\n",
    "print(f\"  Difference: {p_test - p_control:.4f}\")\n",
    "print(f\"  Z-statistic: {z_retention:.4f}\")\n",
    "print(f\"  P-value: {p_value_retention:.4f}\")\n",
    "if p_value_retention < alpha:\n",
    "    print(f\"  Result: Statistically significant improvement in D1 Retention at alpha={alpha}\")\n",
    "else:\n",
    "    print(f\"  Result: No statistically significant improvement in D1 Retention at alpha={alpha}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# 3. Calculate the power of the test for both metrics. Decide whether the test had sufficient sample size.\n",
    "\n",
    "## 3.1 Power for ARPI_D1\n",
    "\n",
    "# To calculate power, we need:\n",
    "# - Alpha level (significance level)\n",
    "# - Effect size (observed difference)\n",
    "# - Standard deviation of the metric (or standard error of the difference)\n",
    "# - Sample size\n",
    "\n",
    "# Given our previous assumption for std_dev_user_revenue, we can calculate power.\n",
    "# Effect size (delta) = diff_arpi\n",
    "# Standard deviation of the difference (sigma_diff) = se_diff_arpi\n",
    "# Z_alpha/2 for two-tailed test\n",
    "alpha = 0.05\n",
    "beta = 0.2 # Common target for 80% power\n",
    "z_alpha_div_2 = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "# Power formula for two-sample Z-test:\n",
    "# Power = 1 - Phi( (Z_alpha/2 * sigma_diff - delta) / sigma_diff ) + Phi( (-Z_alpha/2 * sigma_diff - delta) / sigma_diff )\n",
    "# Simplified formula for power with observed effect:\n",
    "# power = 1 - norm.cdf(Z_crit - Z_observed) + norm.cdf(-Z_crit - Z_observed)  (approximate, or use direct formula for power)\n",
    "\n",
    "# From a power calculation perspective, we typically calculate power given a *minimum detectable effect (MDE)*.\n",
    "# If we want to calculate the power of the *actual* test that was run with the observed effect,\n",
    "# we can use the observed effect size.\n",
    "\n",
    "# Power for observed ARPI_D1 difference\n",
    "# For a two-tailed test, power is given by:\n",
    "# P(Z > z_alpha/2 | H1 is true) + P(Z < -z_alpha/2 | H1 is true)\n",
    "# where Z under H1 is (observed_diff - true_diff) / SE_diff + delta/SE_diff (if assuming delta is true)\n",
    "# Let's use the observed diff as the true effect for power calculation.\n",
    "\n",
    "# Non-centrality parameter (NCP) approach for power:\n",
    "# delta / SE_diff = Z_observed\n",
    "# z_beta = z_alpha_div_2 - z_arpi (if one-sided)\n",
    "\n",
    "# Power calculation using statsmodels for more accuracy or manual formula.\n",
    "# For simplicity, let's use the z-score approach directly.\n",
    "# Calculate power for the observed effect size.\n",
    "power_arpi = stats.norm.cdf(z_arpi - z_alpha_div_2) + stats.norm.cdf(-z_arpi - z_alpha_div_2)\n",
    "# The above formula is for power given true effect size = diff_arpi.\n",
    "# A simpler, direct power for observed effect:\n",
    "# p_power_arpi = stats.norm.cdf(z_arpi - z_alpha_div_2)\n",
    "\n",
    "# More accurate calculation for power given observed effect in two-tailed test:\n",
    "# power = stats.norm.cdf(z_arpi - z_alpha_div_2) + (1 - stats.norm.cdf(z_arpi + z_alpha_div_2)) # if z_arpi is positive\n",
    "# if z_arpi is negative:\n",
    "# power = stats.norm.cdf(-z_arpi - z_alpha_div_2) + (1 - stats.norm.cdf(-z_arpi + z_alpha_div_2))\n",
    "\n",
    "# A standard way to calculate power using the observed effect as the true effect:\n",
    "# For two-tailed test, power is approximately 1 - beta.\n",
    "# where beta = stats.norm.cdf( (z_alpha_div_2 * se_diff_arpi - diff_arpi) / se_diff_arpi )  # if diff_arpi is positive\n",
    "# This is tricky because `stats.tt_ind_solve_power` from `statsmodels.stats.power` is more suitable.\n",
    "# Since we are not using statsmodels, let's use a common manual approximation or specific formula.\n",
    "\n",
    "# Let's use the formula for power given the observed effect and sample size:\n",
    "# Power = 1 - beta\n",
    "# where beta = P(Type II error)\n",
    "# For a two-tailed test, we reject if |Z| > Z_critical.\n",
    "# Power = P(|Z_observed| > Z_critical | H1 is true)\n",
    "# If the true effect is `delta`, and the observed effect is `diff_arpi`.\n",
    "# For power calculation, we usually hypothesize a *true* effect size. Let's use the observed `diff_arpi` as our hypothesized true effect.\n",
    "\n",
    "# Calculate critical Z-value\n",
    "z_critical = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "# Power calculation using a commonly found formula for observed effect as true effect:\n",
    "# From https://stats.stackexchange.com/questions/213512/how-to-calculate-power-for-a-two-sample-t-test-given-summary-statistics\n",
    "# d_prime = diff_arpi / se_diff_arpi # This is our Z-statistic.\n",
    "# power_arpi = stats.norm.cdf(d_prime - z_critical) + stats.norm.cdf(-d_prime - z_critical) # this is assuming one-sided then adjusting.\n",
    "# The previous version was simplified. Let's use standard power calculation for a given effect size.\n",
    "\n",
    "# Power for ARPI_D1\n",
    "# To calculate power, we need the effect size (difference in means) and the standard deviation of the difference.\n",
    "# Effect size = diff_arpi (0.03)\n",
    "# se_diff_arpi (based on assumed s_ind_revenue_assumed = 1.5) = 0.000212\n",
    "\n",
    "# Standard error of the difference for a two-sample Z-test:\n",
    "# se_diff = sqrt(sigma1^2/n1 + sigma2^2/n2)\n",
    "# Here, sigma1 and sigma2 are assumed to be s_ind_revenue_assumed.\n",
    "# se_diff_arpi = np.sqrt((s_ind_revenue_assumed**2 / n_control) + (s_ind_revenue_assumed**2 / n_test))\n",
    "# se_diff_arpi = np.sqrt((1.5**2 / 10000) + (1.5**2 / 10000)) = 0.021213\n",
    "\n",
    "# This was the correct value. Let's re-calculate se_diff_arpi using the same assumed s_ind_revenue_assumed.\n",
    "se_diff_arpi = np.sqrt((s_ind_revenue_assumed**2 / n_control) + (s_ind_revenue_assumed**2 / n_test))\n",
    "# This is the same se_diff_arpi as used before.\n",
    "\n",
    "# Power for a two-sided test given effect size (diff_arpi) and standard error of difference (se_diff_arpi)\n",
    "# We need to calculate the value of z_beta (critical z-value for beta)\n",
    "# z_beta = (Effect Size - Z_critical * SE_diff) / SE_diff  (for one-sided)\n",
    "# For two-sided:\n",
    "# Power = stats.norm.cdf( (diff_arpi / se_diff_arpi) - z_critical ) + stats.norm.cdf( (-diff_arpi / se_diff_arpi) - z_critical )\n",
    "# This is valid if diff_arpi is positive.\n",
    "power_arpi_calculated = stats.norm.cdf(z_arpi - z_critical) + (1 - stats.norm.cdf(z_arpi + z_critical))\n",
    "# Given z_arpi is already the ratio diff/se_diff, this is:\n",
    "# power_arpi_calculated = stats.norm.cdf(z_arpi - z_critical) + stats.norm.cdf(-z_arpi - z_critical)\n",
    "# This is the correct power calculation based on the observed effect size for a two-tailed test.\n",
    "\n",
    "print(f\"Power for ARPI_D1 (based on observed effect and assumed individual revenue std dev = ${s_ind_revenue_assumed}):\")\n",
    "print(f\"  Observed Effect (diff_arpi): {diff_arpi:.4f}\")\n",
    "print(f\"  Standard Error of Difference (SE_diff_arpi): {se_diff_arpi:.4f}\")\n",
    "print(f\"  Calculated Power: {power_arpi_calculated:.4f}\")\n",
    "\n",
    "# Sample size calculation for ARPI_D1 (for 80% power and observed effect)\n",
    "# Formula: N = ( (Z_alpha/2 + Z_beta)^2 * (sigma1^2 + sigma2^2) ) / (delta^2)\n",
    "# Assuming sigma1 = sigma2 = s_ind_revenue_assumed\n",
    "# N_per_group = (Z_alpha/2 + Z_beta)^2 * (2 * s_ind_revenue_assumed^2) / (diff_arpi^2)\n",
    "# Z_beta for 80% power (beta=0.2) is stats.norm.ppf(0.8) for one-sided, or stats.norm.ppf(1-0.2) for two-sided (power is 1-beta, so 0.8 is the value)\n",
    "# z_beta = stats.norm.ppf(0.8) # For 80% power (one-sided)\n",
    "z_beta = stats.norm.ppf(0.8) # For 80% power (beta=0.2)\n",
    "# For a two-tailed test, Z_beta is calculated from the Type II error rate (beta).\n",
    "# If power is 0.8, then beta is 0.2. So we use stats.norm.ppf(1-0.2) or stats.norm.ppf(0.8).\n",
    "\n",
    "# For two-sided test, sample size formula:\n",
    "# n_per_group = ((z_critical + z_beta)**2 * 2 * s_ind_revenue_assumed**2) / (diff_arpi**2)\n",
    "required_n_arpi = ((z_critical + z_beta)**2 * 2 * (s_ind_revenue_assumed**2)) / (diff_arpi**2)\n",
    "print(f\"  Required Sample Size per group for 80% Power (ARPI_D1): {int(np.ceil(required_n_arpi)):,}\")\n",
    "print(f\"  Current Sample Size per group: {n_control:,}\")\n",
    "if n_control >= required_n_arpi:\n",
    "    print(\"  Conclusion: Sufficient sample size for ARPI_D1 (based on observed effect and assumed std dev).\")\n",
    "else:\n",
    "    print(\"  Conclusion: Insufficient sample size for ARPI_D1 (based on observed effect and assumed std dev).\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "## 3.2 Power for D1 Retention\n",
    "\n",
    "# Effect size (delta) = p_test - p_control\n",
    "# Standard error of the difference (sigma_diff) = se_diff_retention\n",
    "# For proportions, the standard error is sqrt(p_pooled * (1-p_pooled) * (1/n1 + 1/n2))\n",
    "\n",
    "# Power calculation for D1 Retention\n",
    "# z_critical = stats.norm.ppf(1 - alpha/2) (already calculated)\n",
    "power_retention_calculated = stats.norm.cdf(z_retention - z_critical) + (1 - stats.norm.cdf(z_retention + z_critical))\n",
    "# This assumes z_retention is positive. If z_retention is negative, flip the sign in front of it.\n",
    "# Given z_retention (already calculated using p_test - p_control), we use it directly.\n",
    "\n",
    "print(\"Power for D1 Retention (based on observed effect):\")\n",
    "print(f\"  Observed Effect (diff_retention): {p_test - p_control:.4f}\")\n",
    "print(f\"  Standard Error of Difference (SE_diff_retention): {se_diff_retention:.4f}\")\n",
    "print(f\"  Calculated Power: {power_retention_calculated:.4f}\")\n",
    "\n",
    "# Sample size calculation for D1 Retention (for 80% power and observed effect)\n",
    "# Formula for proportion:\n",
    "# n_per_group = ((Z_alpha/2 + Z_beta)^2 * (p1*(1-p1) + p2*(1-p2))) / (delta^2)\n",
    "# A more common way uses pooled variance for effect size, or average of p1 and p2.\n",
    "# Let's use the standard formula for required sample size for proportions:\n",
    "# n_per_group = ((z_critical + z_beta)**2 * (p_control*(1-p_control) + p_test*(1-p_test))) / ((p_test - p_control)**2)\n",
    "# Here, we use the observed proportions p_control and p_test as the 'true' proportions for the MDE.\n",
    "required_n_retention = ((z_critical + z_beta)**2 * (p_control*(1-p_control) + p_test*(1-p_test))) / ((p_test - p_control)**2)\n",
    "print(f\"  Required Sample Size per group for 80% Power (D1 Retention): {int(np.ceil(required_n_retention)):,}\")\n",
    "print(f\"  Current Sample Size per group: {n_control:,}\")\n",
    "if n_control >= required_n_retention:\n",
    "    print(\"  Conclusion: Sufficient sample size for D1 Retention (based on observed effect).\")\n",
    "else:\n",
    "    print(\"  Conclusion: Insufficient sample size for D1 Retention (based on observed effect).\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Summarize findings and recommendation\n",
    "\n",
    "print(\"--- Summary of Findings and Recommendation ---\")\n",
    "\n",
    "print(\"1. Statistical Significance Assessment:\")\n",
    "print(f\"   - ARPI_D1: P-value = {p_value_arpi:.4f}. With alpha = {alpha}, the feature is {'statistically significant' if p_value_arpi < alpha else 'NOT statistically significant'} for ARPI_D1.\")\n",
    "print(\"     (Note: This result for ARPI_D1 is based on an assumed standard deviation of individual D1 revenue. In a real scenario, this assumption would need to be validated with granular data.)\")\n",
    "print(f\"   - D1 Retention: P-value = {p_value_retention:.4f}. With alpha = {alpha}, the feature is {'statistically significant' if p_value_retention < alpha else 'NOT statistically significant'} for D1 Retention.\")\n",
    "\n",
    "print(\"\\n2. Power of the Test and Sample Size:\")\n",
    "print(f\"   - ARPI_D1: Calculated Power = {power_arpi_calculated:.4f}. Required sample size for 80% power for the observed effect = {int(np.ceil(required_n_arpi)):,}.\")\n",
    "if n_control >= required_n_arpi:\n",
    "    print(\"     The current sample size of 10,000 users per group was sufficient for ARPI_D1 (given the assumed individual revenue std dev).\")\n",
    "else:\n",
    "    print(\"     The current sample size of 10,000 users per group was INSUFFICIENT for ARPI_D1 (given the assumed individual revenue std dev).\")\n",
    "print(f\"   - D1 Retention: Calculated Power = {power_retention_calculated:.4f}. Required sample size for 80% power for the observed effect = {int(np.ceil(required_n_retention)):,}.\")\n",
    "if n_control >= required_n_retention:\n",
    "    print(\"     The current sample size of 10,000 users per group was sufficient for D1 Retention.\")\n",
    "else:\n",
    "    print(\"     The current sample size of 10,000 users per group was INSUFFICIENT for D1 Retention.\")\n",
    "\n",
    "print(\"\\n3. Recommendation:\")\n",
    "if p_value_retention < alpha and p_value_arpi < alpha: # Both significant\n",
    "    print(\"a. Should the feature be rolled out? YES.\")\n",
    "    print(\"b. Is there enough evidence? YES. Both D1 Retention and ARPI_D1 show a statistically significant improvement.\")\n",
    "elif p_value_retention < alpha and p_value_arpi >= alpha: # Retention significant, ARPI not\n",
    "    print(\"a. Should the feature be rolled out? CONSIDER CAREFULLY. While D1 Retention shows a statistically significant improvement, ARPI_D1 does not (based on the current assumptions).\")\n",
    "    print(\"b. Is there enough evidence? Partially. There is strong evidence for D1 Retention improvement. For ARPI_D1, the evidence is not strong enough for statistical significance under the current assumptions.\")\n",
    "    print(\"c. If not significant (for ARPI_D1):\")\n",
    "    print(\"   - Investigate the assumed individual revenue standard deviation for ARPI_D1 more accurately, potentially by getting granular user-level data.\")\n",
    "    print(\"   - If the current data setup is robust, consider running the test for a longer duration to gather more data and increase the sample size effectively, or increase the sample size for a new test.\")\n",
    "    print(\"   - Analyze qualitative feedback about the feature to understand user perception and identify potential reasons for non-significant ARPI improvement.\")\n",
    "    print(\"   - Re-evaluate the feature's potential business impact. If the D1 retention uplift is valuable enough on its own, it might warrant rollout even without ARPI_D1 significance, but this depends on business priorities.\")\n",
    "elif p_value_retention >= alpha and p_value_arpi < alpha: # ARPI significant, Retention not\n",
    "    print(\"a. Should the feature be rolled out? CONSIDER CAREFULLY. While ARPI_D1 shows a statistically significant improvement (based on assumptions), D1 Retention does not.\")\n",
    "    print(\"b. Is there enough evidence? Partially. There is strong evidence for ARPI_D1 improvement (under current assumptions). For D1 Retention, the evidence is not strong enough.\")\n",
    "    print(\"c. If not significant (for D1 Retention):\")\n",
    "    print(\"   - Analyze why retention was not impacted. Is the feature engaging enough? Are there any bugs or usability issues?\")\n",
    "    print(\"   - Consider iterating on the feature to improve retention, or gather more data to see if the current trend reaches significance with a larger sample.\")\n",
    "    print(\"   - If the ARPI_D1 uplift is deemed very valuable, and the D1 retention is not worse, it might still be considered for rollout, but with monitoring.\")\n",
    "else: # Neither significant\n",
    "    print(\"a. Should the feature be rolled out? NO, NOT YET.\")\n",
    "    print(\"b. Is there enough evidence? NO. Neither D1 Retention nor ARPI_D1 show a statistically significant improvement.\")\n",
    "    print(\"c. If not significant, what would you do next?\")\n",
    "    print(\"   - Conduct a deeper dive into user behavior within the test group to understand why the feature didn't perform as expected. This could involve qualitative research (surveys, user interviews).\")\n",
    "    print(\"   - Check for implementation issues or bugs in the feature that might be skewing results.\")\n",
    "    print(\"   - Refine the feature based on insights and re-run the A/B test with an updated version.\")\n",
    "    print(\"   - Consider increasing the sample size for a new test or extending the duration of the current test if the observed effect sizes are close to the minimum detectable effect you'd be interested in.\")\n",
    "    print(\"   - Re-evaluate the initial hypothesis for the feature. Is it truly expected to impact these KPIs?\")\n",
    "    print(\"   - Explore other KPIs that might be affected by the feature that were not measured in this test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f10a66-9369-4324-9699-52a4ca93653a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
